{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKL Take on the Home Credit Default Risk Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in imports\n",
    "import os\n",
    "# 3p imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "# custom imports\n",
    "from helper_functions import load_data_frame, flag_columns_to_bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_application_train = os.path.join(\"./\", \"home-credit-default-risk\", \"application_train.csv\")\n",
    "\n",
    "df = load_data_frame(path_application_train)\n",
    "original_size = df.shape\n",
    "null_count_df = df.isna().sum() # vypsani statistik poctu chybejicicih hodnot\n",
    "null_count_df == 0 # funguje, vrati tabulku statistik s bool hodnotami\n",
    "df = df.dropna() # odmaze vsechny null radky, no made-up data approach\n",
    "no_null_shape = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. If I understand the meaning, columns with \"FLAG\" string in the name are binary columns denoting presence of lack there of a certain variable. Thus I decide to replace the string \"Y\"/\"N\" values and integer 1/0 with proper boolean values (this may also lead to reduced memory usage, but this is not the main motivation).\n",
    "2. The rest of the string variables (dtype(\"O\")) needs to be properly encoded in order for the scikitlearn algorithms to be able to handle them. I need some analogy to OneHotEncoder for categorical and OrdinalEncoder for oridnal data. An example of categorical data is the \"CODE_GENDER\" or \"NAME_HOUSING_TYPE\". Perhaps the first one mentioned should be removed in future version of the model, because preserving it may lead to a sexist classifier. On the other hand, there are clearly some more ordinalish features, such as \"NAME_EDUCATION_TYPE\" where a certain commonly agreed ordering does exist (there is much bigger difference between \"Primary\" and \"Masters\" level than between \"Doctorate\" and \"Masters\"). I sould look up for ordinal features and encode them accordingly in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8602, 122)\n",
      "(8602, 122)\n",
      "(8602, 234)\n"
     ]
    }
   ],
   "source": [
    "# deal with the boolean features\n",
    "print(df.shape)\n",
    "df = flag_columns_to_bool(df)\n",
    "print(df.shape)\n",
    "df = pd.get_dummies(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6451, 233)\n",
      "(6451,)\n"
     ]
    }
   ],
   "source": [
    "y = df[\"TARGET\"]\n",
    "X = df.drop([\"TARGET\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1408  611]\n",
      " [  88   44]]\n"
     ]
    }
   ],
   "source": [
    "baseline_classifier = MLPClassifier().fit(X_train, y_train)\n",
    "y_pred = baseline_classifier.predict(X_test)\n",
    "cf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(cf_mat)\n",
    "print(matthews_corrcoef(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
