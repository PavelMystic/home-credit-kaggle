{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKL Take on the Home Credit Default Risk Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in imports\n",
    "import os\n",
    "# 3p imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "# custom imports\n",
    "from helper_functions import load_data_frame, flag_columns_to_bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_application_train = os.path.join(\"./\", \"home-credit-default-risk\", \"application_train.csv\")\n",
    "\n",
    "df = load_data_frame(path_application_train)\n",
    "df = df.sample(n=100000)\n",
    "original_size = df.shape\n",
    "\n",
    "# initialize target vector and feature matrix\n",
    "y = df[\"TARGET\"]\n",
    "X = df.drop([\"TARGET\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Handling\n",
    "\n",
    "If we try to omit all of the missing data (i.e. omit samples, where there is at least one missing feature) we discover, that we have reduced the dataset brutally, from approx $3 \\times 10^{5}$ samples to less than $1 \\times 10^{3}$ samples. While in some cases, omitting samples with some missing features might not be that big of a problem, in this case the dataset might loose its usability for any analysis whatsoever. This discovery leads to the necessity of missin data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY                       2\n",
      "AMT_GOODS_PRICE                  99\n",
      "NAME_TYPE_SUITE                 424\n",
      "OWN_CAR_AGE                   66125\n",
      "OCCUPATION_TYPE               31342\n",
      "                              ...  \n",
      "AMT_REQ_CREDIT_BUREAU_DAY     13565\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK    13565\n",
      "AMT_REQ_CREDIT_BUREAU_MON     13565\n",
      "AMT_REQ_CREDIT_BUREAU_QRT     13565\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR    13565\n",
      "Length: 66, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count_df = df.isna().sum() # vypsani statistik poctu chybejicicih hodnot\n",
    "# df = df.dropna() # odmaze vsechny null radky, no made-up data approach\n",
    "# no_null_shape = df.shape\n",
    "print(null_count_df[null_count_df > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. The rest of the string variables (dtype(\"O\")) needs to be properly encoded in order for the scikitlearn algorithms to be able to handle them. I need some analogy to OneHotEncoder for categorical and OrdinalEncoder for oridnal data. An example of categorical data is the \"CODE_GENDER\" or \"NAME_HOUSING_TYPE\". Perhaps the first one mentioned should be removed in future version of the model, because preserving it may lead to a sexist classifier. On the other hand, there are clearly some more ordinalish features, such as \"NAME_EDUCATION_TYPE\" where a certain commonly agreed ordering does exist (there is much bigger difference between \"Primary\" and \"Masters\" level than between \"Doctorate\" and \"Masters\"). I sould look up for ordinal features and encode them accordingly in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = make_column_transformer(\n",
    "    (SimpleImputer(missing_values=np.NaN, strategy=\"median\"), list(X.select_dtypes(include=\"int64\").columns)),\n",
    "    (make_pipeline(SimpleImputer(missing_values=np.NaN, strategy=\"mean\"), StandardScaler()), \n",
    "        list(X.select_dtypes(include=\"float64\").columns)),\n",
    "    (make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"), SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")), \n",
    "        list(X.select_dtypes(include=\"object\")))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 121)\n",
      "(75000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pipeline = make_pipeline(column_transformer, MLPClassifier())\n",
    "# cross_validation_pipeline = make_pipeline(column_transformer, cross_validate(MLPClassifier(), X, y))\n",
    "score = cross_val_score(classifier_pipeline, X, y, cv=10)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
