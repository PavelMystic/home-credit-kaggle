{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKL Take on the Home Credit Default Risk Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in imports\n",
    "import os\n",
    "# 3p imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "# custom imports\n",
    "from helper_functions import load_data_frame, flag_columns_to_bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_application_train = os.path.join(\"./\", \"home-credit-default-risk\", \"application_train.csv\")\n",
    "\n",
    "df = load_data_frame(path_application_train)\n",
    "original_size = df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Handling\n",
    "\n",
    "If we try to omit all of the missing data (i.e. omit samples, where there is at least one missing feature) we discover, that we have reduced the dataset brutally, from approx $3 \\times 10^{5}$ samples to less than $1 \\times 10^{3}$ samples. While in some cases, omitting samples with some missing features might not be that big of a problem, in this case the dataset might loose its usability for any analysis whatsoever. This discovery leads to the necessity of missin data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY                       12\n",
      "AMT_GOODS_PRICE                  278\n",
      "NAME_TYPE_SUITE                 1292\n",
      "OWN_CAR_AGE                   202929\n",
      "OCCUPATION_TYPE                96391\n",
      "                               ...  \n",
      "AMT_REQ_CREDIT_BUREAU_DAY      41519\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK     41519\n",
      "AMT_REQ_CREDIT_BUREAU_MON      41519\n",
      "AMT_REQ_CREDIT_BUREAU_QRT      41519\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR     41519\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count_df = df.isna().sum() # vypsani statistik poctu chybejicicih hodnot\n",
    "# df = df.dropna() # odmaze vsechny null radky, no made-up data approach\n",
    "# no_null_shape = df.shape\n",
    "print(null_count_df[null_count_df > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
      "0              Cash loans           M            N               Y   \n",
      "1              Cash loans           F            N               N   \n",
      "2         Revolving loans           M            Y               Y   \n",
      "3              Cash loans           F            N               Y   \n",
      "4              Cash loans           M            N               Y   \n",
      "...                   ...         ...          ...             ...   \n",
      "307506         Cash loans           M            N               N   \n",
      "307507         Cash loans           F            N               Y   \n",
      "307508         Cash loans           F            N               Y   \n",
      "307509         Cash loans           F            N               Y   \n",
      "307510         Cash loans           F            N               N   \n",
      "\n",
      "       NAME_TYPE_SUITE      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "0        Unaccompanied               Working  Secondary / secondary special   \n",
      "1               Family         State servant               Higher education   \n",
      "2        Unaccompanied               Working  Secondary / secondary special   \n",
      "3        Unaccompanied               Working  Secondary / secondary special   \n",
      "4        Unaccompanied               Working  Secondary / secondary special   \n",
      "...                ...                   ...                            ...   \n",
      "307506   Unaccompanied               Working  Secondary / secondary special   \n",
      "307507   Unaccompanied             Pensioner  Secondary / secondary special   \n",
      "307508   Unaccompanied               Working               Higher education   \n",
      "307509   Unaccompanied  Commercial associate  Secondary / secondary special   \n",
      "307510   Unaccompanied  Commercial associate               Higher education   \n",
      "\n",
      "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE OCCUPATION_TYPE  ...  \\\n",
      "0       Single / not married  House / apartment        Laborers  ...   \n",
      "1                    Married  House / apartment      Core staff  ...   \n",
      "2       Single / not married  House / apartment        Laborers  ...   \n",
      "3             Civil marriage  House / apartment        Laborers  ...   \n",
      "4       Single / not married  House / apartment      Core staff  ...   \n",
      "...                      ...                ...             ...  ...   \n",
      "307506             Separated       With parents     Sales staff  ...   \n",
      "307507                 Widow  House / apartment        Laborers  ...   \n",
      "307508             Separated  House / apartment        Managers  ...   \n",
      "307509               Married  House / apartment        Laborers  ...   \n",
      "307510               Married  House / apartment        Laborers  ...   \n",
      "\n",
      "       DEF_30_CNT_SOCIAL_CIRCLE OBS_60_CNT_SOCIAL_CIRCLE  \\\n",
      "0                           2.0                      2.0   \n",
      "1                           0.0                      1.0   \n",
      "2                           0.0                      0.0   \n",
      "3                           0.0                      2.0   \n",
      "4                           0.0                      0.0   \n",
      "...                         ...                      ...   \n",
      "307506                      0.0                      0.0   \n",
      "307507                      0.0                      0.0   \n",
      "307508                      0.0                      6.0   \n",
      "307509                      0.0                      0.0   \n",
      "307510                      0.0                      0.0   \n",
      "\n",
      "       DEF_60_CNT_SOCIAL_CIRCLE DAYS_LAST_PHONE_CHANGE  \\\n",
      "0                           2.0                -1134.0   \n",
      "1                           0.0                 -828.0   \n",
      "2                           0.0                 -815.0   \n",
      "3                           0.0                 -617.0   \n",
      "4                           0.0                -1106.0   \n",
      "...                         ...                    ...   \n",
      "307506                      0.0                 -273.0   \n",
      "307507                      0.0                    0.0   \n",
      "307508                      0.0                -1909.0   \n",
      "307509                      0.0                 -322.0   \n",
      "307510                      0.0                 -787.0   \n",
      "\n",
      "       AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
      "0                        0.000000                     0.000   \n",
      "1                        0.000000                     0.000   \n",
      "2                        0.000000                     0.000   \n",
      "3                        0.006402                     0.007   \n",
      "4                        0.000000                     0.000   \n",
      "...                           ...                       ...   \n",
      "307506                   0.006402                     0.007   \n",
      "307507                   0.006402                     0.007   \n",
      "307508                   1.000000                     0.000   \n",
      "307509                   0.000000                     0.000   \n",
      "307510                   0.000000                     0.000   \n",
      "\n",
      "        AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
      "0                         0.000000                   0.000000   \n",
      "1                         0.000000                   0.000000   \n",
      "2                         0.000000                   0.000000   \n",
      "3                         0.034362                   0.267395   \n",
      "4                         0.000000                   0.000000   \n",
      "...                            ...                        ...   \n",
      "307506                    0.034362                   0.267395   \n",
      "307507                    0.034362                   0.267395   \n",
      "307508                    0.000000                   1.000000   \n",
      "307509                    0.000000                   0.000000   \n",
      "307510                    0.000000                   2.000000   \n",
      "\n",
      "        AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
      "0                        0.000000                    1.000000  \n",
      "1                        0.000000                    0.000000  \n",
      "2                        0.000000                    0.000000  \n",
      "3                        0.265474                    1.899974  \n",
      "4                        0.000000                    0.000000  \n",
      "...                           ...                         ...  \n",
      "307506                   0.265474                    1.899974  \n",
      "307507                   0.265474                    1.899974  \n",
      "307508                   0.000000                    1.000000  \n",
      "307509                   0.000000                    0.000000  \n",
      "307510                   0.000000                    1.000000  \n",
      "\n",
      "[307511 rows x 122 columns]\n",
      "AMT_ANNUITY                       12\n",
      "AMT_GOODS_PRICE                  278\n",
      "NAME_TYPE_SUITE                 1292\n",
      "OWN_CAR_AGE                   202929\n",
      "OCCUPATION_TYPE                96391\n",
      "                               ...  \n",
      "AMT_REQ_CREDIT_BUREAU_DAY      41519\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK     41519\n",
      "AMT_REQ_CREDIT_BUREAU_MON      41519\n",
      "AMT_REQ_CREDIT_BUREAU_QRT      41519\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR     41519\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dtype_list = list(set(df.dtypes))\n",
    "imputed_df_list = []\n",
    "\n",
    "for dtype in dtype_list:\n",
    "    df_dtype = df.select_dtypes(include=dtype)\n",
    "\n",
    "    match str(dtype):\n",
    "\n",
    "        case \"int64\":\n",
    "\n",
    "            # for integer values median is more reasobable, because it has to be one of the values, \n",
    "            # while the mean might be integer in general\n",
    "            imputer = SimpleImputer(missing_values=np.NaN, strategy=\"median\")\n",
    "\n",
    "        case \"float64\":\n",
    "\n",
    "            # it may be benefitial to estimate skeweness of each particular float feature to asses \n",
    "            # whether or not it is a good idea to use mean value\n",
    "            imputer = SimpleImputer(missing_values=np.NaN, strategy=\"mean\")\n",
    "\n",
    "        case \"object\":\n",
    "\n",
    "            imputer = SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")\n",
    "\n",
    "    imputed_df_list.append(pd.DataFrame(imputer.fit_transform(df_dtype)))\n",
    "    imputed_df_list[-1].columns = df_dtype.columns\n",
    "    imputed_df_list[-1].index = df_dtype.index\n",
    "\n",
    "df_imputed = imputed_df_list[0].join(imputed_df_list[1:])\n",
    "print(df_imputed)\n",
    "null_count_df = df.isna().sum()\n",
    "print(null_count_df[null_count_df > 0])\n",
    "\n",
    "# replace the original data with the new ones\n",
    "df = df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. If I understand the meaning, columns with \"FLAG\" string in the name are binary columns denoting presence of lack there of a certain variable. Thus I decide to replace the string \"Y\"/\"N\" values and integer 1/0 with proper boolean values (this may also lead to reduced memory usage, but this is not the main motivation).\n",
    "2. The rest of the string variables (dtype(\"O\")) needs to be properly encoded in order for the scikitlearn algorithms to be able to handle them. I need some analogy to OneHotEncoder for categorical and OrdinalEncoder for oridnal data. An example of categorical data is the \"CODE_GENDER\" or \"NAME_HOUSING_TYPE\". Perhaps the first one mentioned should be removed in future version of the model, because preserving it may lead to a sexist classifier. On the other hand, there are clearly some more ordinalish features, such as \"NAME_EDUCATION_TYPE\" where a certain commonly agreed ordering does exist (there is much bigger difference between \"Primary\" and \"Masters\" level than between \"Doctorate\" and \"Masters\"). I sould look up for ordinal features and encode them accordingly in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n",
      "FLAG_OWN_CAR\n",
      "FLAG_OWN_REALTY\n",
      "FLAG_MOBIL\n",
      "FLAG_EMP_PHONE\n",
      "FLAG_WORK_PHONE\n",
      "FLAG_CONT_MOBILE\n",
      "FLAG_PHONE\n",
      "FLAG_EMAIL\n",
      "FLAG_DOCUMENT_2\n",
      "FLAG_DOCUMENT_3\n",
      "FLAG_DOCUMENT_4\n",
      "FLAG_DOCUMENT_5\n",
      "FLAG_DOCUMENT_6\n",
      "FLAG_DOCUMENT_7\n",
      "FLAG_DOCUMENT_8\n",
      "FLAG_DOCUMENT_9\n",
      "FLAG_DOCUMENT_10\n",
      "FLAG_DOCUMENT_11\n",
      "FLAG_DOCUMENT_12\n",
      "FLAG_DOCUMENT_13\n",
      "FLAG_DOCUMENT_14\n",
      "FLAG_DOCUMENT_15\n",
      "FLAG_DOCUMENT_16\n",
      "FLAG_DOCUMENT_17\n",
      "FLAG_DOCUMENT_18\n",
      "FLAG_DOCUMENT_19\n",
      "FLAG_DOCUMENT_20\n",
      "FLAG_DOCUMENT_21\n",
      "(307511, 122)\n",
      "(307511, 244)\n"
     ]
    }
   ],
   "source": [
    "# deal with the boolean features\n",
    "df = flag_columns_to_bool(df)\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230633, 243)\n",
      "(230633,)\n"
     ]
    }
   ],
   "source": [
    "y = df[\"TARGET\"]\n",
    "X = df.drop([\"TARGET\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_classifier = MLPClassifier().fit(X_train, y_train)\n",
    "y_pred = baseline_classifier.predict(X_test)\n",
    "cf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(cf_mat)\n",
    "print(matthews_corrcoef(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
